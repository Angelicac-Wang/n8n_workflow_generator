#!/usr/bin/env python3
"""
ä¸»å”èª¿å™¨

æ•´åˆæ‰€æœ‰çµ„ä»¶ï¼Œæä¾›çµ±ä¸€çš„ API è™•ç†ç”¨æˆ¶æŸ¥è©¢ä¸¦ç”Ÿæˆ n8n å·¥ä½œæµç¨‹ã€‚
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Optional
import yaml

# é¿å… huggingface tokenizers çš„è­¦å‘Š
os.environ["TOKENIZERS_PARALLELISM"] = "false"

from .workflow_system import HybridWorkflowSystem
from ..models.chain_recommender import ChainRecommender
from ..generation.n8n_json_generator import N8nWorkflowGenerator
from ..generation.parameter_filler import ParameterFiller
from ..adapters.node_type_mapper import NodeTypeMapper
from ..utils.file_loader import load_json, load_yaml
from ..utils.logger import setup_logger


class WorkflowOrchestrator:
    """
    å·¥ä½œæµç¨‹å”èª¿å™¨
    
    æ•´åˆç”Ÿæˆå™¨ï¼ˆVincentï¼‰å’Œè©•åˆ†å™¨ï¼ˆDanielï¼‰ï¼Œæä¾›å®Œæ•´çš„æ¨è–¦æµç¨‹ã€‚
    """
    
    def __init__(
        self,
        openai_key: Optional[str] = None,
        config_path: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–å”èª¿å™¨
        
        Args:
            openai_key: OpenAI API å¯†é‘°ï¼ˆå¯é¸ï¼Œå¦‚æœç‚º None æˆ–ç©ºå­—ä¸²ï¼Œæœƒå¾ config.yaml è®€å–ï¼‰
            config_path: é…ç½®æª”æ¡ˆè·¯å¾‘ï¼ˆå¯é¸ï¼‰
        """
        print("\n" + "=" * 80)
        print("Initializing n8n Workflow Recommender Orchestrator")
        print("=" * 80)
        
        # è¼‰å…¥é…ç½®
        if config_path:
            self.config = load_yaml(config_path)
        else:
            # ä½¿ç”¨é»˜èªè·¯å¾‘
            base_dir = Path(__file__).resolve().parent.parent.parent
            config_path = base_dir / "n8n_workflow_recommender" / "config" / "config.yaml"
            self.config = load_yaml(str(config_path))
        
        # å¦‚æœ openai_key ç‚º None æˆ–ç©ºå­—ä¸²ï¼Œå¾ config è®€å–
        if not openai_key or not openai_key.strip():
            config_key = self.config.get('api', {}).get('openai_key', '')
            if config_key and config_key != "YOUR_OPENAI_API_KEY_HERE" and config_key.strip():
                openai_key = config_key
                print("âœ… å¾ config.yaml è®€å– OpenAI API Key")
            else:
                openai_key = ''
                print("âš ï¸  Warning: OpenAI API key not found in config.yaml")
        
        # è¨­å®šè·¯å¾‘
        # åœ¨æ‰“åŒ…ç‰ˆæœ¬ä¸­ï¼Œbase_dir æ˜¯æ‰“åŒ…ç›®éŒ„çš„æ ¹ç›®éŒ„
        base_dir = Path(__file__).resolve().parent.parent.parent
        paths = self.config.get('paths', {})
        
        # ä½¿ç”¨å¸¶æœ‰ example_use_cases çš„ taxonomy
        # å„ªå…ˆä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾‘ï¼Œå¦å‰‡ä½¿ç”¨é»˜èªè·¯å¾‘
        taxonomy_config_path = paths.get('taxonomy_path', '../data/taxonomy_full_with_examples.json')
        if taxonomy_config_path.startswith('../'):
            self.taxonomy_path = base_dir / taxonomy_config_path[3:]
        else:
            self.taxonomy_path = Path(taxonomy_config_path) if Path(taxonomy_config_path).is_absolute() else base_dir / taxonomy_config_path
        
        # çŸ¥è­˜åœ–è·¯å¾‘ï¼ˆåœ¨å¤–éƒ¨ data/ ç›®éŒ„ä¸­ï¼‰
        self.kg_path = base_dir / "data" / "adapted_knowledge_graph.json"
        
        # è™•ç† Matrix Factorization æ¨¡å‹è·¯å¾‘
        matrix_model_path = paths.get('matrix_model_dir', '../models/matrix_factorization')
        # ç§»é™¤ ../ å‰ç¶´
        if matrix_model_path.startswith('../'):
            matrix_model_path = matrix_model_path[3:]
        if not Path(matrix_model_path).is_absolute():
            self.matrix_model_dir = base_dir / matrix_model_path
        else:
            self.matrix_model_dir = Path(matrix_model_path)
        
        # ç¯€é»æ˜ å°„è·¯å¾‘
        self.node_mappings_path = base_dir / "data" / "node_mappings.json"
        
        # è¼‰å…¥æ•¸æ“š
        print("\nğŸ“¥ Loading data...")
        
        # è¼‰å…¥çŸ¥è­˜åœ–
        print(f"   - Loading knowledge graph: {self.kg_path}")
        kg_data = load_json(str(self.kg_path))
        triples = kg_data.get('triples', [])
        ontology = kg_data.get('ontology', {})
        print(f"   âœ… Loaded {len(triples)} triples and {len(ontology)} node types")
        
        # è¼‰å…¥ç¯€é»æ˜ å°„
        print(f"   - Loading node mappings: {self.node_mappings_path}")
        self.node_mapper = NodeTypeMapper(str(self.node_mappings_path))
        print(f"   âœ… Loaded {len(self.node_mapper.name_to_type)} mappings")
        
        # åˆå§‹åŒ–ç”Ÿæˆå™¨ï¼ˆVincentï¼‰
        print("\nğŸ”§ Initializing Generator (Vincent)...")
        # ä½¿ç”¨è™•ç†å¾Œçš„ openai_keyï¼ˆå·²ç¶“å¾ config è®€å–éäº†ï¼‰
        self.generator = HybridWorkflowSystem(
            triples=triples,
            ontology=ontology,
            taxonomy_path=str(self.taxonomy_path),
            openai_api_key=openai_key
        )
        
        # åˆå§‹åŒ–è©•åˆ†å™¨ï¼ˆDanielï¼‰
        print("\nğŸ”§ Initializing Scorer (Daniel)...")
        self.scorer = ChainRecommender(
            model_dir=str(self.matrix_model_dir),
            use_type_model=True
        )
        
        # åˆå§‹åŒ–åƒæ•¸å¡«å……å™¨
        print("\nğŸ”§ Initializing Parameter Filler...")
        self.parameter_filler = ParameterFiller(ontology)
        
        # åˆå§‹åŒ– JSON ç”Ÿæˆå™¨
        print("\nğŸ”§ Initializing JSON Generator...")
        self.json_generator = N8nWorkflowGenerator(self.node_mapper)
        
        print("\nâœ… Orchestrator initialized successfully!")
    
    def process_user_request(self, user_query: str) -> Dict:
        """
        è™•ç†ç”¨æˆ¶è«‹æ±‚
        
        Args:
            user_query: ç”¨æˆ¶æŸ¥è©¢å­—ç¬¦ä¸²
        
        Returns:
            result: {
                "best_workflow": {...},
                "candidates": [...],
                "workflow_json": {...}
            }
        """
        print("\n" + "=" * 80)
        print("Processing User Request")
        print("=" * 80)
        
        # Phase 1: Generation (Vincent)
        print("\nğŸ“ Phase 1: Workflow Generation")
        candidates = self.generator.generate_workflow(user_query)
        
        if not candidates:
            return {
                "error": "ç„¡æ³•ç”Ÿæˆå·¥ä½œæµç¨‹å€™é¸",
                "candidates": []
            }
        
        # Phase 2: Scoring (Daniel)
        print("\nğŸ“Š Phase 2: Workflow Scoring")
        ranked_candidates = self.scorer.rank_candidates(candidates)
        
        if not ranked_candidates:
            return {
                "error": "ç„¡æ³•è©•åˆ†å·¥ä½œæµç¨‹å€™é¸",
                "candidates": []
            }
        
        # Phase 3: Select Best
        print("\nğŸ† Phase 3: Selecting Best Workflow")
        best_candidate = ranked_candidates[0]
        best_path = best_candidate.get('path', [])
        
        print(f"   - Best path: {' -> '.join(best_path)}")
        print(f"   - Score: {best_candidate.get('mf_score', 0.0):.4f}")
        
        # Phase 4: Fill Parameters
        print("\nğŸ”§ Phase 4: Filling Parameters")
        extracted_params = best_candidate.get('params', {})
        chain_params = self.parameter_filler.fill_chain_parameters(
            best_path,
            extracted_params,
            strict=False
        )
        
        # Phase 5: Generate n8n JSON
        print("\nğŸ“„ Phase 5: Generating n8n Workflow JSON")
        workflow_json = self.json_generator.generate_workflow_json(
            node_type_chain=best_path,
            workflow_name="Generated Workflow",
            node_params=chain_params
        )
        
        # æ§‹å»ºçµæœ
        result = {
            "best_workflow": {
                "path": best_path,
                "score": best_candidate.get('mf_score', 0.0),
                "description": best_candidate.get('description', ''),
                "params": chain_params
            },
            "candidates": [
                {
                    "path": c.get('path', []),
                    "score": c.get('mf_score', 0.0),
                    "description": c.get('description', '')
                }
                for c in ranked_candidates[:5]  # åªè¿”å›å‰5å€‹
            ],
            "workflow_json": workflow_json
        }
        
        print("\nâœ… Workflow generation completed!")
        return result
    
    def save_result(self, result: Dict, output_path: str):
        """
        ä¿å­˜çµæœåˆ°æª”æ¡ˆ
        
        Args:
            result: çµæœå­—å…¸
            output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ Result saved to: {output_path}")


def main():
    """ä¸»å‡½æ•¸ï¼šæ¸¬è©¦å”èª¿å™¨"""
    import sys
    import os
    
    # æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
    base_dir = Path(__file__).resolve().parent.parent.parent
    sys.path.insert(0, str(base_dir))
    
    # è¨­å®šè·¯å¾‘
    config_path = base_dir / "n8n_workflow_recommender" / "config" / "config.yaml"
    
    # å¾é…ç½®è¼‰å…¥ API key
    config = load_yaml(str(config_path))
    openai_key = config.get('api', {}).get('openai_key', '')
    
    if not openai_key:
        print("âŒ Error: OpenAI API key not found in config.yaml")
        return
    
    # åˆå§‹åŒ–å”èª¿å™¨
    orchestrator = WorkflowOrchestrator(
        openai_key=openai_key,
        config_path=str(config_path)
    )
    
    # æ¸¬è©¦æŸ¥è©¢
    user_query = "è¨­è¨ˆæ™ºèƒ½ä¿¡ä»¶è™•ç†æµç¨‹ï¼Œç•¶æœ‰æ–°gmailä¿¡ä»¶é€²ä¾†æ™‚è‡ªå‹•è§¸ç™¼ï¼Œä½¿ç”¨ openai ç†è§£ä¿¡ä»¶å…§å®¹ï¼Œå¦‚æœèˆ‡é–‹æœƒç›¸é—œï¼Œå‰‡æå–é–‹å§‹æ™‚é–“ã€çµæŸæ™‚é–“ã€åœ°é»å­˜å…¥google calendarã€‚"
    
    # è™•ç†è«‹æ±‚
    result = orchestrator.process_user_request(user_query)
    
    # ä¿å­˜çµæœ
    output_dir = base_dir / "output"
    output_dir.mkdir(exist_ok=True)
    output_path = output_dir / "test_result.json"
    orchestrator.save_result(result, str(output_path))
    
    print("\n" + "=" * 80)
    print("Test completed!")
    print("=" * 80)


if __name__ == "__main__":
    main()

