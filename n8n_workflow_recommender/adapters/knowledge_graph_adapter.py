#!/usr/bin/env python3
"""
é©é…çŸ¥è­˜åœ–æ ¼å¼

å°‡å¾ templates æå–çš„çŸ¥è­˜åœ– triples è½‰æ›ç‚º DomainKnowledgeGraph å¯ç”¨çš„æ ¼å¼ã€‚
è™•ç†ç¯€é»åç¨±åˆ°ç¯€é»é¡å‹çš„è½‰æ›ï¼Œå»ºç«‹ NetworkX åœ–çµæ§‹ã€‚
"""

import json
from pathlib import Path
from typing import List, Tuple, Dict, Set, Optional
import networkx as nx


def load_triples(triples_path: str) -> List[Tuple[str, str, str]]:
    """
    è¼‰å…¥çŸ¥è­˜åœ–ä¸‰å…ƒçµ„
    
    Args:
        triples_path: triples JSON æª”æ¡ˆè·¯å¾‘
    
    Returns:
        triples: [(head, relation, tail), ...]
    """
    triples_path = Path(triples_path)
    
    if not triples_path.exists():
        raise FileNotFoundError(f"Triples æª”æ¡ˆä¸å­˜åœ¨: {triples_path}")
    
    with open(triples_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
        return data.get("triples", [])


def load_node_mappings(mappings_path: str) -> Dict[str, str]:
    """
    è¼‰å…¥ç¯€é»åç¨±åˆ°é¡å‹çš„æ˜ å°„
    
    Args:
        mappings_path: mappings JSON æª”æ¡ˆè·¯å¾‘
    
    Returns:
        name_to_type: {node_name: node_type}
    """
    mappings_path = Path(mappings_path)
    
    if not mappings_path.exists():
        raise FileNotFoundError(f"Mappings æª”æ¡ˆä¸å­˜åœ¨: {mappings_path}")
    
    with open(mappings_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
        return data.get("name_to_type", {})


def load_ontology(ontology_path: str) -> Dict:
    """
    è¼‰å…¥ Ontology
    
    Args:
        ontology_path: ontology JSON æª”æ¡ˆè·¯å¾‘
    
    Returns:
        ontology: {node_type: {"required_params": [...], ...}}
    """
    ontology_path = Path(ontology_path)
    
    if not ontology_path.exists():
        raise FileNotFoundError(f"Ontology æª”æ¡ˆä¸å­˜åœ¨: {ontology_path}")
    
    with open(ontology_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
        return data.get("ontology", {})


def convert_triples_to_node_types(
    triples: List[Tuple[str, str, str]],
    name_to_type: Dict[str, str]
) -> Tuple[List[Tuple[str, str, str]], Dict[str, str]]:
    """
    å°‡ç¯€é»åç¨±çš„ triples è½‰æ›ç‚ºç¯€é»é¡å‹çš„ triples
    
    Args:
        triples: ç¯€é»åç¨±çš„ä¸‰å…ƒçµ„åˆ—è¡¨
        name_to_type: ç¯€é»åç¨±åˆ°é¡å‹çš„æ˜ å°„
    
    Returns:
        (type_triples, name_to_type_mapping): 
        - type_triples: ç¯€é»é¡å‹çš„ä¸‰å…ƒçµ„åˆ—è¡¨
        - name_to_type_mapping: å®Œæ•´çš„æ˜ å°„ï¼ˆåŒ…å«æœªçŸ¥ç¯€é»ï¼‰
    """
    type_triples = []
    unknown_nodes = set()
    
    for head, relation, tail in triples:
        head_type = name_to_type.get(head)
        tail_type = name_to_type.get(tail)
        
        # åªä¿ç•™å…©å€‹ç¯€é»éƒ½æœ‰é¡å‹æ˜ å°„çš„ triples
        if head_type and tail_type:
            type_triples.append((head_type, relation, tail_type))
        else:
            if not head_type:
                unknown_nodes.add(head)
            if not tail_type:
                unknown_nodes.add(tail)
    
    if unknown_nodes:
        print(f"   âš ï¸  è·³éäº† {len(unknown_nodes)} å€‹æœªçŸ¥ç¯€é»çš„ triples")
    
    return type_triples, dict(name_to_type)


def build_ontology_for_types(
    type_ontology: Dict
) -> Dict[str, Dict]:
    """
    ç‚ºç¯€é»é¡å‹å»ºç«‹ Ontologyï¼ˆç›´æ¥ä½¿ç”¨é¡å‹ Ontologyï¼‰
    
    Args:
        type_ontology: ç¯€é»é¡å‹çš„ Ontology
    
    Returns:
        type_ontology: {node_type: {"required_params": [...], ...}}
    """
    # ç›´æ¥è¿”å›é¡å‹ Ontologyï¼Œå› ç‚ºæˆ‘å€‘ç¾åœ¨ä½¿ç”¨ç¯€é»é¡å‹è€Œä¸æ˜¯ç¯€é»åç¨±
    return type_ontology


def build_networkx_graph(
    triples: List[Tuple[str, str, str]],
    ontology: Optional[Dict] = None
) -> nx.DiGraph:
    """
    å¾ triples å»ºç«‹ NetworkX æœ‰å‘åœ–
    
    Args:
        triples: ä¸‰å…ƒçµ„åˆ—è¡¨
        ontology: å¯é¸çš„ Ontology å­—å…¸ï¼ˆç”¨æ–¼æ·»åŠ ç¯€é»å±¬æ€§ï¼‰
    
    Returns:
        graph: NetworkX æœ‰å‘åœ–
    """
    graph = nx.DiGraph()
    
    # æ·»åŠ æ‰€æœ‰ç¯€é»
    all_nodes = set([h for h, _, _ in triples] + [t for _, _, t in triples])
    for node in all_nodes:
        node_attrs = {}
        if ontology and node in ontology:
            node_attrs = ontology[node].copy()
        graph.add_node(node, **node_attrs)
    
    # æ·»åŠ æ‰€æœ‰é‚Š
    for head, relation, tail in triples:
        graph.add_edge(head, tail, relation=relation, weight=1.0)
    
    return graph


def get_graph_statistics(graph: nx.DiGraph) -> Dict:
    """
    ç²å–åœ–çš„çµ±è¨ˆè³‡è¨Š
    
    Args:
        graph: NetworkX åœ–
    
    Returns:
        stats: çµ±è¨ˆè³‡è¨Šå­—å…¸
    """
    return {
        "num_nodes": graph.number_of_nodes(),
        "num_edges": graph.number_of_edges(),
        "is_connected": nx.is_weakly_connected(graph),
        "num_components": nx.number_weakly_connected_components(graph),
        "density": nx.density(graph),
        "average_degree": sum(dict(graph.degree()).values()) / graph.number_of_nodes() if graph.number_of_nodes() > 0 else 0
    }


def save_adapted_knowledge_graph(
    triples: List[Tuple[str, str, str]],
    ontology: Dict,
    output_path: str
):
    """
    ä¿å­˜é©é…å¾Œçš„çŸ¥è­˜åœ–
    
    Args:
        triples: ä¸‰å…ƒçµ„åˆ—è¡¨
        ontology: Ontology å­—å…¸
        output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
    """
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    data = {
        "triples": triples,
        "ontology": ontology,
        "statistics": {
            "num_triples": len(triples),
            "num_nodes": len(ontology),
            "unique_relations": list(set([r for _, r, _ in triples]))
        }
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ é©é…å¾Œçš„çŸ¥è­˜åœ–å·²ä¿å­˜åˆ°: {output_path}")


def main():
    """ä¸»å‡½æ•¸ï¼šé©é…çŸ¥è­˜åœ–"""
    # è¨­å®šè·¯å¾‘ï¼ˆç›¸å°æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼‰
    base_dir = Path(__file__).resolve().parent.parent.parent
    triples_path = base_dir / "n8n_workflow_recommender" / "data" / "knowledge_graph_triples.json"
    mappings_path = base_dir / "n8n_workflow_recommender" / "data" / "node_mappings.json"
    ontology_path = base_dir / "n8n_workflow_recommender" / "data" / "ontology.json"
    output_path = base_dir / "n8n_workflow_recommender" / "data" / "adapted_knowledge_graph.json"
    
    print("=" * 80)
    print("n8n Knowledge Graph Adapter")
    print("=" * 80)
    
    # è¼‰å…¥æ•¸æ“š
    print(f"\nğŸ“¥ è¼‰å…¥çŸ¥è­˜åœ–ä¸‰å…ƒçµ„ï¼ˆç¯€é»åç¨±ï¼‰: {triples_path}")
    name_triples = load_triples(str(triples_path))
    print(f"   âœ… è¼‰å…¥äº† {len(name_triples)} å€‹ä¸‰å…ƒçµ„ï¼ˆç¯€é»åç¨±ï¼‰")
    
    print(f"\nğŸ“¥ è¼‰å…¥ç¯€é»æ˜ å°„: {mappings_path}")
    name_to_type = load_node_mappings(str(mappings_path))
    print(f"   âœ… è¼‰å…¥äº† {len(name_to_type)} å€‹ç¯€é»æ˜ å°„")
    
    print(f"\nğŸ“¥ è¼‰å…¥ Ontology: {ontology_path}")
    type_ontology = load_ontology(str(ontology_path))
    print(f"   âœ… è¼‰å…¥äº† {len(type_ontology)} å€‹ç¯€é»é¡å‹çš„ Ontology")
    
    # è½‰æ› triples ç‚ºç¯€é»é¡å‹ï¼ˆé‡è¦ï¼šèˆ‡åŸå§‹ç³»çµ±ä¸€è‡´ï¼‰
    print("\nğŸ”„ å°‡ç¯€é»åç¨± triples è½‰æ›ç‚ºç¯€é»é¡å‹ triples...")
    type_triples, _ = convert_triples_to_node_types(name_triples, name_to_type)
    print(f"   âœ… è½‰æ›å¾Œå¾—åˆ° {len(type_triples)} å€‹ç¯€é»é¡å‹çš„ä¸‰å…ƒçµ„")
    
    # ä½¿ç”¨ç¯€é»é¡å‹çš„ Ontologyï¼ˆèˆ‡åŸå§‹ç³»çµ±ä¸€è‡´ï¼‰
    print("\nğŸ”„ ä½¿ç”¨ç¯€é»é¡å‹çš„ Ontology...")
    ontology = build_ontology_for_types(type_ontology)
    print(f"   âœ… ä½¿ç”¨ {len(ontology)} å€‹ç¯€é»é¡å‹çš„ Ontology")
    
    # å»ºç«‹ NetworkX åœ–ï¼ˆä½¿ç”¨ç¯€é»é¡å‹ï¼‰
    print("\nğŸ”„ å»ºç«‹ NetworkX åœ–ï¼ˆç¯€é»é¡å‹ï¼‰...")
    graph = build_networkx_graph(type_triples, ontology)
    stats = get_graph_statistics(graph)
    print(f"   âœ… åœ–çµ±è¨ˆ:")
    print(f"      - ç¯€é»æ•¸: {stats['num_nodes']}")
    print(f"      - é‚Šæ•¸: {stats['num_edges']}")
    print(f"      - é€£é€šåˆ†é‡æ•¸: {stats['num_components']}")
    print(f"      - å¯†åº¦: {stats['density']:.4f}")
    
    # ä¿å­˜é©é…å¾Œçš„çŸ¥è­˜åœ–ï¼ˆä½¿ç”¨ç¯€é»é¡å‹ï¼‰
    save_adapted_knowledge_graph(type_triples, ontology, str(output_path))
    
    print("\nâœ… å®Œæˆï¼")


if __name__ == "__main__":
    main()

