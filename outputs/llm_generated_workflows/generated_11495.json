{
  "template_id": "11495",
  "llm_response": {
    "mode": "create_workflow",
    "workflowPlan": {
      "name": "AI Prompt Optimization Workflow",
      "nodes": [
        {
          "id": "1",
          "label": "Define Initial Prompt & Test Data",
          "nodeType": "n8n-nodes-base.set",
          "typeVersion": 1,
          "params": {
            "values": {
              "string": [
                {
                  "name": "initial_prompt",
                  "value": "Your initial prompt here"
                },
                {
                  "name": "test_input",
                  "value": "Your test input here"
                },
                {
                  "name": "ground_truth",
                  "value": "Your expected ground truth here"
                }
              ]
            }
          },
          "position": {
            "x": 200,
            "y": 300
          }
        },
        {
          "id": "2",
          "label": "Generate Response",
          "nodeType": "n8n-nodes-base.OpenAI",
          "typeVersion": 1,
          "params": {
            "model": "text-davinci-003",
            "prompt": "={{$json[\"initial_prompt\"]}}",
            "input": "={{$json[\"test_input\"]}}"
          },
          "position": {
            "x": 400,
            "y": 300
          }
        },
        {
          "id": "3",
          "label": "Evaluate Response",
          "nodeType": "n8n-nodes-base.OpenAI",
          "typeVersion": 1,
          "params": {
            "model": "text-davinci-003",
            "prompt": "Evaluate the response: {{$json[\"response\"]}} against the ground truth: {{$json[\"ground_truth\"]}} and score it from 0 to 100."
          },
          "position": {
            "x": 600,
            "y": 300
          }
        },
        {
          "id": "4",
          "label": "Optimize Prompt",
          "nodeType": "n8n-nodes-base.OpenAI",
          "typeVersion": 1,
          "params": {
            "model": "text-davinci-003",
            "prompt": "Analyze the failure in the response: {{$json[\"response\"]}} and suggest a better prompt."
          },
          "position": {
            "x": 800,
            "y": 300
          }
        },
        {
          "id": "5",
          "label": "Manage Loop & State",
          "nodeType": "n8n-nodes-base.if",
          "typeVersion": 1,
          "params": {
            "conditions": {
              "number": [
                {
                  "value1": "={{$json[\"score\"]}}",
                  "operation": "greaterThan",
                  "value2": 95
                }
              ]
            }
          },
          "position": {
            "x": 1000,
            "y": 300
          }
        }
      ],
      "connections": [
        {
          "from": "1",
          "to": "2"
        },
        {
          "from": "2",
          "to": "3"
        },
        {
          "from": "3",
          "to": "4",
          "outputIndex": 1
        },
        {
          "from": "4",
          "to": "5"
        },
        {
          "from": "5",
          "to": "2",
          "outputIndex": 0,
          "inputIndex": 1
        }
      ]
    }
  },
  "usage": {
    "prompt_tokens": 824,
    "completion_tokens": 772,
    "total_tokens": 1596
  },
  "error": null,
  "generated_at": "2026-01-11T16:51:37.287822"
}